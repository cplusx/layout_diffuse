{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "from pytorch_lightning import Trainer\n",
    "from train_sample_utils import get_models, get_DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-c', '--config', type=str, \n",
    "    default='config/train.json')\n",
    "parser.add_argument(\n",
    "    '-n', '--num_repeat', type=int, \n",
    "    default=1, help='the number of images for each condition')\n",
    "parser.add_argument(\n",
    "    '-cond', '--condition', action='store_true',\n",
    "    help='whether for unconditional sampling or conditional sampling (for some dataset)'\n",
    ")\n",
    "\n",
    "''' parser configs '''\n",
    "args_raw = parser.parse_args(['-c', 'configs/coco_ldm_soft_partial_prompt_animal_subset.json'])\n",
    "with open(args_raw.config, 'r') as IN:\n",
    "    args = json.load(IN)\n",
    "args.update(vars(args_raw))\n",
    "# args['gpu_ids'] = [0] # DEBUG\n",
    "expt_name = args['expt_name']\n",
    "expt_dir = args['expt_dir']\n",
    "expt_path = os.path.join(expt_dir, expt_name)\n",
    "os.makedirs(expt_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. create denoising model'''\n",
    "denoise_args = args['denoising_model']['model_args']\n",
    "models = get_models(args)\n",
    "\n",
    "diffusion_configs = args['diffusion']\n",
    "# diffusion_args['beta_schedule_args']['n_timestep'] = 10 # DEBUG\n",
    "ddpm_model = get_DDPM(\n",
    "    diffusion_configs=diffusion_configs,\n",
    "    log_args=args,\n",
    "    **models\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. create a dataloader which generates'''\n",
    "from test_sample_utils import get_test_dataset, get_test_callbacks\n",
    "test_dataset, test_loader = get_test_dataset(args)\n",
    "\n",
    "'''3. callbacks'''\n",
    "callbacks = get_test_callbacks(args, expt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(expt_path, 'latest.ckpt')\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(f'INFO: Found checkpoint {ckpt_path}')\n",
    "    ckpt = torch.load(ckpt_path)['state_dict']\n",
    "    ''' DEBUG '''\n",
    "    # ckpt_denoise_fn = {k.replace('denoise_fn.', ''): v for k, v in ckpt.items() if 'denoise_fn' in k}\n",
    "    # ddpm_model.denoise_fn.load_state_dict(ckpt_denoise_fn)\n",
    "    ddpm_model.load_state_dict(ckpt)\n",
    "else:\n",
    "    ckpt_path = None\n",
    "    raise RuntimeError('Cannot do inference without pretrained checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "ANIMAL_ID_MAPPING = {\n",
    "    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse',\n",
    "    20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',\n",
    "    24: 'zebra', 25: 'giraffe' \n",
    "}\n",
    "class ColorMapping():\n",
    "    def __init__(self, id_class_mapping, mesh_dim=3):\n",
    "        self.id_class_mapping = id_class_mapping\n",
    "        num_classes = len(id_class_mapping)\n",
    "        num_grid_each_dim = math.ceil(num_classes**(1/mesh_dim))\n",
    "        mesh_d = np.meshgrid(\n",
    "            *[np.linspace(0,1,num_grid_each_dim)]*mesh_dim\n",
    "        )\n",
    "        mesh_d = [i.reshape(-1) for i in mesh_d]\n",
    "        self.mesh = np.stack(mesh_d, axis=-1)\n",
    "\n",
    "        self.id_to_mesh_idx = {}\n",
    "        for idx, (class_id, class_name) in enumerate(id_class_mapping.items()):\n",
    "            self.id_to_mesh_idx[class_id] = idx\n",
    "    \n",
    "    def __call__(self, class_id):\n",
    "        class_name = self.id_class_mapping[class_id]\n",
    "        mesh_index = self.id_to_mesh_idx[class_id]\n",
    "        return self.mesh[mesh_index], class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "def format_image(x):\n",
    "    x = x.cpu()\n",
    "    x = (x + 1) / 2\n",
    "    x = x.clamp(0, 1)\n",
    "    assert len(x.shape) in [3, 4]\n",
    "    if len(x.shape) == 3:\n",
    "        x = x.permute(1,2,0).detach().numpy()\n",
    "    else:\n",
    "        if x.shape[0] == 1:\n",
    "            x = x[0].permute(1,2,0).detach().numpy()\n",
    "        else:\n",
    "            x = make_grid(x)\n",
    "            x = x.permute(1,2,0).detach().numpy()\n",
    "    return x\n",
    "def show_image(x):\n",
    "    plt.imshow(format_image(x))\n",
    "\n",
    "def plot_bounding_box(image, bboxes, label_mapping=ANIMAL_ID_MAPPING):\n",
    "    # bboxes: num_obj, 5\n",
    "    color_mapper = ColorMapping(label_mapping)\n",
    "\n",
    "    H, W = image.shape[:2]\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox[:4]\n",
    "        x, y, w, h = list(map(int, [x*W, y*H, w*W, h*H]))\n",
    "        label = int(bbox[-1]) + 1 if len(bbox) == 5 else None\n",
    "        # in the network, we let label start from 0 by -1, now we add 1 back\n",
    "        color, class_name = color_mapper(label)\n",
    "        # plot the rectangle bounding box and label\n",
    "        image = cv2.rectangle(image, (int(x), int(y)), (int(x+w), int(y+h)), color, 2)\n",
    "        if label:\n",
    "            (w, h), _ = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 1)\n",
    "            image = cv2.rectangle(image, (x, y+20), (x + w, y), color, -1)\n",
    "            cv2.putText(image, class_name, (x, y+18), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (1,1,1), 1)\n",
    "    return image\n",
    "\n",
    "def save_image(image, save_path):\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    if image.dtype == np.float32:\n",
    "        image = (image * 255).astype(np.uint8)[..., ::-1]\n",
    "    cv2.imwrite(save_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(test_loader):\n",
    "    images = batch[0].cuda()\n",
    "    context = torch.tensor(batch[1]).cuda()\n",
    "    random_image = torch.randn(1, 3, 64, 64).cuda()\n",
    "    res = ddpm_model.fast_sampling(\n",
    "        noise=random_image, \n",
    "        model_kwargs={'context': context}, \n",
    "    )\n",
    "    y_0_hat = res[0]\n",
    "\n",
    "    #start plot\n",
    "    image = format_image(y_0_hat)\n",
    "    bboxes = batch[1][0]\n",
    "    image_annoed = plot_bounding_box(image.copy(), torch.tensor(bboxes).numpy(), ANIMAL_ID_MAPPING)\n",
    "\n",
    "    save_image(\n",
    "        image_annoed, \n",
    "        save_path=os.path.join(expt_path, 'sampling', f'{idx:04d}.png')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.coco_detect import get_coco_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_coco_id_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'person',\n",
       " 2: 'bicycle',\n",
       " 3: 'car',\n",
       " 4: 'motorcycle',\n",
       " 5: 'airplane',\n",
       " 6: 'bus',\n",
       " 7: 'train',\n",
       " 8: 'truck',\n",
       " 9: 'boat',\n",
       " 10: 'traffic light',\n",
       " 11: 'fire hydrant',\n",
       " 13: 'stop sign',\n",
       " 14: 'parking meter',\n",
       " 15: 'bench',\n",
       " 16: 'bird',\n",
       " 17: 'cat',\n",
       " 18: 'dog',\n",
       " 19: 'horse',\n",
       " 20: 'sheep',\n",
       " 21: 'cow',\n",
       " 22: 'elephant',\n",
       " 23: 'bear',\n",
       " 24: 'zebra',\n",
       " 25: 'giraffe',\n",
       " 27: 'backpack',\n",
       " 28: 'umbrella',\n",
       " 31: 'handbag',\n",
       " 32: 'tie',\n",
       " 33: 'suitcase',\n",
       " 34: 'frisbee',\n",
       " 35: 'skis',\n",
       " 36: 'snowboard',\n",
       " 37: 'sports ball',\n",
       " 38: 'kite',\n",
       " 39: 'baseball bat',\n",
       " 40: 'baseball glove',\n",
       " 41: 'skateboard',\n",
       " 42: 'surfboard',\n",
       " 43: 'tennis racket',\n",
       " 44: 'bottle',\n",
       " 46: 'wine glass',\n",
       " 47: 'cup',\n",
       " 48: 'fork',\n",
       " 49: 'knife',\n",
       " 50: 'spoon',\n",
       " 51: 'bowl',\n",
       " 52: 'banana',\n",
       " 53: 'apple',\n",
       " 54: 'sandwich',\n",
       " 55: 'orange',\n",
       " 56: 'broccoli',\n",
       " 57: 'carrot',\n",
       " 58: 'hot dog',\n",
       " 59: 'pizza',\n",
       " 60: 'donut',\n",
       " 61: 'cake',\n",
       " 62: 'chair',\n",
       " 63: 'couch',\n",
       " 64: 'potted plant',\n",
       " 65: 'bed',\n",
       " 67: 'dining table',\n",
       " 70: 'toilet',\n",
       " 72: 'tv',\n",
       " 73: 'laptop',\n",
       " 74: 'mouse',\n",
       " 75: 'remote',\n",
       " 76: 'keyboard',\n",
       " 77: 'cell phone',\n",
       " 78: 'microwave',\n",
       " 79: 'oven',\n",
       " 80: 'toaster',\n",
       " 81: 'sink',\n",
       " 82: 'refrigerator',\n",
       " 84: 'book',\n",
       " 85: 'clock',\n",
       " 86: 'vase',\n",
       " 87: 'scissors',\n",
       " 88: 'teddy bear',\n",
       " 89: 'hair drier',\n",
       " 90: 'toothbrush'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### visualize prediction results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
